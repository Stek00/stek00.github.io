---
title: Homework 6
date: 2024-11-06 20:00:00 +0800
categories: [homeworks, statistics]
tags: [hw]     # TAG names should always be lowercase
---


# The Fundamental Theorem of Calculus and Its Relationship to Density Functions and CDFs

## The Fundamental Theorem of Calculus (FTC)

The **FTC** bridges differentiation and integration. It states:

$$\int_a^b f(x) \, dx = F(b) - F(a)$$

where $$ f(x) $$ is a continuous function on $$[a, b]$$, and $$ F(x) $$ is an antiderivative of $$ f(x) $$ (i.e., $$ F'(x) = f(x) $$).

This fundamental relationship plays a crucial role in probability theory, particularly in connecting **probability density functions (PDFs)** with **cumulative distribution functions (CDFs)**.

---

## Key Definitions

### 1. **Probability Density Function (PDF)**
A PDF, $$ f_X(x) $$, describes the relative likelihood of a random variable $$ X $$ taking a specific value. For a **continuous random variable**, the probability of $$ X $$ lying in an interval $$[a, b]$$ is given by:

$$P(a \leq X \leq b) = \int_a^b f_X(x) \, dx.$$

The total area under the PDF over the entire domain equals 1, ensuring a valid probability distribution.

### 2. **Cumulative Distribution Function (CDF)**
A CDF, $$ F_X(x) $$, gives the probability that $$ X $$ takes on a value less than or equal to $$ x $$:

$$F_X(x) = P(X \leq x) = \int_{-\infty}^x f_X(t) \, dt.$$

The CDF accumulates probabilities over the interval $$(-\infty, x]$$.

---

## Relationship Between PDF and CDF

Using the **FTC**, we see:

1. **The CDF is the integral of the PDF:**
   $$F_X(x) = \int_{-\infty}^x f_X(t) \, dt.$$

2. **The PDF is the derivative of the CDF (if  $$F_X(x)$$  is differentiable):**
   $$f_X(x) = \frac{d}{dx} F_X(x).$$

This relationship highlights how the FTC provides the mathematical foundation for understanding the connection between these two functions.

---

## Interpretation

1. The **PDF** describes the *instantaneous rate of change* of the **CDF**. At any point $$ x $$, $$ f_X(x) $$ measures how quickly the probability $$ P(X \leq x) $$ is accumulating.
   
2. The **CDF** aggregates probabilities over the range $$(-\infty, x]$$, while the **PDF** focuses on the density of probability at each specific $$ x $$.

---

## Example: A Specific PDF and CDF

Consider a random variable $$ X $$ with the PDF:

$$
f_X(x) = 
\begin{cases} 
2x & \text{if } 0 \leq x \leq 1, \\
0 & \text{otherwise}.
\end{cases}
$$

### Step 1: Finding the CDF

The CDF $$ F_X(x) $$ is found by integrating $$ f_X(x) $$:

$$
F_X(x) = \int_{-\infty}^x f_X(t) \, dt.
$$

Breaking this into cases:

$$
F_X(x) = 
\begin{cases}
0 & \text{if } x < 0, \\
\int_0^x 2t \, dt = t^2 \big|_0^x = x^2 & \text{if } 0 \leq x \leq 1, \\
1 & \text{if } x > 1.
\end{cases}
$$

Thus:

$$
F_X(x) = 
\begin{cases}
0 & \text{if } x < 0, \\
x^2 & \text{if } 0 \leq x \leq 1, \\
1 & \text{if } x > 1.
\end{cases}
$$

### Step 2: Verifying the PDF

Taking the derivative of $$ F_X(x) $$ confirms the PDF:

$$
f_X(x) = \frac{d}{dx} F_X(x) = 
\begin{cases}
2x & \text{if } 0 \leq x \leq 1, \\
0 & \text{otherwise}.
\end{cases}
$$

---

## Summary

- The **CDF** accumulates probabilities, while the **PDF** provides the rate at which these probabilities change.
- The **FTC** provides the theoretical framework linking these two functions in probability theory, ensuring consistency and coherence in their definitions and applications.


## Practice

![Desktop View](/assets/Program6.png){: w="700" h="400" }

[The source code for the application can be found here](https://github.com/Stek00/stek00.github.io/tree/main/Homework_6)

Theoretical values are derived from a probability distribution and represent the expected long-term averages or probabilities based on mathematical models. These values are calculated using formulas and assumptions about the underlying distribution of the data, providing an idealized framework for understanding behavior over infinite repetitions or trials.

Empirical values, on the other hand, are obtained directly from observed data or samples generated in a specific experiment or simulation. These values reflect the actual outcomes and can vary depending on the sample size, randomness, and underlying conditions of the sampling process.

As the sample size increases, empirical values tend to converge toward their theoretical counterparts. This phenomenon is explained by the **Law of Large Numbers**, which states that the averages of observed values from a sufficiently large sample will approach the expected value predicted by the probability distribution. Essentially, larger sample sizes reduce the effect of random fluctuations and provide a more accurate representation of the theoretical model.

The discrepancies between theoretical and empirical values are an important measure of how well a sample represents the underlying distribution. These differences can arise due to sampling variability, limited sample size, or biases in the sampling process. Analyzing these differences can provide valuable insights into the reliability of the sampling method and the accuracy of the theoretical assumptions.

In general, larger sample sizes lead to smaller differences between theoretical and empirical values. This is because a larger dataset captures more information about the population, reducing the impact of random noise and improving the precision of empirical estimates. Consequently, increasing the sample size is a common approach to enhancing the accuracy of statistical analyses and validating theoretical models.